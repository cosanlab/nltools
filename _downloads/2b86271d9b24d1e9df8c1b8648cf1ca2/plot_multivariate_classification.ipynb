{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multivariate Classification\n\nThis tutorial provides an example of how to run classification analyses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load & Prepare Data\n\nFirst, let's load the pain data for this example.  We need to create a data \nobject with high and low pain intensities.  These labels need to be specified in the\ndat.Y field as a pandas dataframe. We also need to create a vector of subject ids\nso that subject images can be held out together in cross-validation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nltools.datasets import fetch_pain\nimport numpy as np\nimport pandas as pd\n\ndata = fetch_pain()\nhigh = data[np.where(data.X['PainLevel']==3)[0]]\nlow = data[np.where(data.X['PainLevel']==1)[0]]\ndat = high.append(low)\ndat.Y = pd.DataFrame(np.concatenate([np.ones(len(high)),np.zeros(len(low))]))\nsubject_id = np.concatenate([high.X['SubjectID'].values,low.X['SubjectID'].values])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification with Cross-Validation\n\nWe can now train a brain model to classify the different labels specified in dat.Y.\nFirst, we will use a support vector machine with 5 fold cross-validation in which the \nsame images from each subject are held out together.  \nThe predict function runs the classification multiple times. One of the \niterations uses all of the data to calculate the 'weight_map'. The other iterations \nestimate the cross-validated predictive accuracy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "svm_stats = dat.predict(algorithm='svm', \n\t\t\t\t\t\tcv_dict={'type': 'kfolds','n_folds': 5, 'subject_id':subject_id},\n\t\t\t\t\t\t**{'kernel':\"linear\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVMs can be converted to predicted probabilities using Platt Scaling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "platt_stats = dat.predict(algorithm='svm', \n\t\t\t\t\t\tcv_dict={'type': 'kfolds','n_folds': 5, 'subject_id':subject_id},\n    \t\t\t\t\t**{'kernel':'linear','probability':True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standard OLS Logistic Regression.  \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logistic_stats = dat.predict(algorithm='logistic', \n    \t\t\t\t\tcv_dict={'type': 'kfolds','n_folds': 5, 'subject_id':subject_id})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ridge classification\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ridge_stats = dat.predict(algorithm='ridgeClassifier', \n    cv_dict={'type': 'kfolds','n_folds': 5, 'subject_id':subject_id})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROC Analyses\n\nWe are often interested in evaluating how well a pattern can discriminate \nbetween different classes of data. However, accuracy could be high because\nof a highly sensitive but not specific model.  Receiver operator characteristic\ncurves allow us to evaluate the sensitivity and specificity of the model.  \nand evaluate how well it can discriminate between high and low pain using \nWe use the Roc class to initialize an Roc object and the plot() and summary() \nmethods to run the analyses. We could also just run the calculate() method \nto run the analysis without plotting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from nltools.analysis import Roc\n\nroc = Roc(input_values=svm_stats['dist_from_hyperplane_xval'], \n\t\tbinary_outcome=svm_stats['Y'].astype(bool))\nroc.plot()\nroc.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above example uses single-interval classification, which attempts to \ndetermine the optimal classification interval. However, sometimes we are \nintersted in directly comparing responses to two images within the same person. \nIn this situation we should use forced-choice classification, which looks at \nthe relative classification accuracy between two images.  You must pass a list \nindicating the ids of each unique subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "roc_fc = Roc(input_values=svm_stats['dist_from_hyperplane_xval'], \n\t\t\tbinary_outcome=svm_stats['Y'].astype(bool), forced_choice=subject_id)\nroc_fc.plot()\nroc_fc.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}